{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\VISHAL SINGH\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Input,Dropout\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import SimpleRNN, RNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Pierre', 'Vinken', ',', '61', 'years', 'old'...</td>\n",
       "      <td>['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Els...</td>\n",
       "      <td>['NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Rudolph', 'Agnew', ',', '55', 'years', 'old'...</td>\n",
       "      <td>['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', 'CC', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['A', 'form', 'of', 'asbestos', 'once', 'used'...</td>\n",
       "      <td>['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', '-NONE-'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['The', 'asbestos', 'fiber', ',', 'crocidolite...</td>\n",
       "      <td>['DT', 'NN', 'NN', ',', 'NN', ',', 'VBZ', 'RB'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokenized_sentences  \\\n",
       "0  ['Pierre', 'Vinken', ',', '61', 'years', 'old'...   \n",
       "1  ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Els...   \n",
       "2  ['Rudolph', 'Agnew', ',', '55', 'years', 'old'...   \n",
       "3  ['A', 'form', 'of', 'asbestos', 'once', 'used'...   \n",
       "4  ['The', 'asbestos', 'fiber', ',', 'crocidolite...   \n",
       "\n",
       "                                                tags  \n",
       "0  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'M...  \n",
       "1  ['NNP', 'NNP', 'VBZ', 'NN', 'IN', 'NNP', 'NNP'...  \n",
       "2  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', 'CC', '...  \n",
       "3  ['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', '-NONE-'...  \n",
       "4  ['DT', 'NN', 'NN', ',', 'NN', ',', 'VBZ', 'RB'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"WSJ_treebank_corpus.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words 1st sentence : 18\n"
     ]
    }
   ],
   "source": [
    "#Converting strings to list for each sentence in the data set\n",
    "tokenized_sentences=df['tokenized_sentences']\n",
    "X=np.array([ eval(x) for x in tokenized_sentences],dtype=object)\n",
    "print(\"Number of words 1st sentence : \"+str(len(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags in 1st sentence : 18\n"
     ]
    }
   ],
   "source": [
    "tags=df['tags']\n",
    "Y=np.array([ eval(x) for x in tags],dtype=object)\n",
    "print(\"Number of tags in 1st sentence : \"+str(len(Y[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The number of tags for a particular sentence = number of words for that sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing the length of every sentence and its corresponding set of tags\n",
    "all([len(X[i])==len(Y[i]) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing the inputs and the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5601,\n",
       " 3746,\n",
       " 1,\n",
       " 2024,\n",
       " 86,\n",
       " 331,\n",
       " 1,\n",
       " 46,\n",
       " 2405,\n",
       " 2,\n",
       " 131,\n",
       " 27,\n",
       " 6,\n",
       " 2025,\n",
       " 332,\n",
       " 459,\n",
       " 2026,\n",
       " 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing the tokenizer\n",
    "word_tokenizer = Tokenizer()   \n",
    "word_tokenizer.fit_on_texts(X) \n",
    "#tokenizing input based on index of every word in vocab set\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X) \n",
    "X_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_tokenizer = Tokenizer()\n",
    "tags_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tags_tokenizer.texts_to_sequences(Y) # tokenizing each tag based on index in tag vocab.\n",
    "Y_encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of tags present in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TAGS=len(tags_tokenizer.word_counts)\n",
    "NUM_TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total Number of words present in dataset\n",
    "len(word_tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if length of each encoded vector and it encoded tag vector are same or not\n",
    "all_of_length = all([len(X_encoded[i])==len(Y[i]) for i in range(len(X_encoded))])\n",
    "all_of_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the length of different sequences in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (14, 8)) \n",
    "lengths_enc = [len(seq) for seq in X_encoded]\n",
    "sns.histplot(lengths_enc,color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the sentence vectors are of variable length we need to add padding and make all of same length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length vector among the all the encoded vector is 271\n"
     ]
    }
   ],
   "source": [
    "max_len_enc=max(lengths_enc)\n",
    "print(\"The maximum length vector among the all the encoded vector is {}\".format(max_len_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 5601, 3746,    1, 2024,   86,  331,\n",
       "          1,   46, 2405,    2,  131,   27,    6, 2025,  332,  459, 2026,\n",
       "          3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting the MAX_VEC_LENGTH to be 100 such that vectors(sequences) greater than 100 in length\n",
    "#will be truncated and for smaller vector zeroes will padded from the left\n",
    "MAX_VEC_LENGTH = 100\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_VEC_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "X_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  8,\n",
       "       10,  6,  7,  8, 21, 13,  4,  1,  2,  4,  7,  1,  3, 10,  9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_VEC_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Assigning to X and Y for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading word2vec with vocab_limit of 20,000 for faster loading \n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',limit=20000, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM  = 300  #Representing each word as a 300 dimensional vector in word2vec\n",
    "VOCAB_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# Empty embedding matrix\n",
    "embedding_weights = np.zeros((VOCAB_SIZE, EMBED_DIM))\n",
    "\n",
    "# Word to index dictionary mapping\n",
    "word2id = word_tokenizer.word_index\n",
    "\n",
    "# copying vectors from word2vec model to the words present in corpus\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Embeddings is : (11388, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Embeddings is : {}\".format(embedding_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoding for the POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3914, 100, 47)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(Y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN with word (embedding weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train,Y_train,X_test,Y_test):\n",
    "    Validation_Size=0.1 #Validation Split Size\n",
    "    #Train - Validation Set Split\n",
    "    X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=Validation_Size, random_state=1)\n",
    "    # total number of tags\n",
    "    NUM_CLASSES = Y.shape[2]\n",
    "    rnn_model = Sequential()\n",
    "\n",
    "    # Embedding layer - using the word2vec weights having dimension Vocab_size x Embed_dim\n",
    "    rnn_model.add(Embedding(input_dim     =  VOCAB_SIZE,         \n",
    "                            output_dim    =  EMBED_DIM,          \n",
    "                            input_length  =  MAX_VEC_LENGTH,         \n",
    "                            weights       = [embedding_weights],      \n",
    "                            trainable     =  True                     # True - update the embeddings while training\n",
    "    ))\n",
    "\n",
    "    # Adding the RNN Layer containg 128 cells\n",
    "    rnn_model.add(SimpleRNN(128, \n",
    "                  return_sequences=True  # True to return whole sequence output \n",
    "    ))\n",
    "    rnn_model.add(Dropout(0.2)) # Adding dropout to avoid overfitting\n",
    "\n",
    "    # Adding TimeDistributed layer - Softmax output based on number of classes or tags\n",
    "    rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))\n",
    "\n",
    "    #Compiling model\n",
    "    rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                      optimizer =  'adam',\n",
    "                      metrics   =  ['acc'])\n",
    "    \n",
    "    print(\"Training - Validation(development) - Test set details :\")\n",
    "    \n",
    "    # printing the number of samples in each set\n",
    "    print(\"Training Set\")\n",
    "    print('Input Shape is : {}'.format(X_train.shape))\n",
    "    print('Output Shape is : {}'.format(Y_train.shape))\n",
    "    print(\"*\"*70)\n",
    "    \n",
    "    print(\"Validation(Development) Set\")\n",
    "    print('Input Shape is : {}'.format(X_validation.shape))\n",
    "    print('Output Shape is : {}'.format(Y_validation.shape))\n",
    "    print(\"*\"*70)\n",
    "    \n",
    "    print(\"Testing Set\")\n",
    "    print('Input Shape is : {}'.format(X_test.shape))\n",
    "    print('Output Shape is : {}'.format(Y_test.shape))\n",
    "    \n",
    "    # model summary\n",
    "    rnn_model.summary()\n",
    "    #Hyper-parameters for the model\n",
    "    epochs=15\n",
    "    batch_size=64\n",
    "    \n",
    "\n",
    "    #Fitting Model\n",
    "    rnn_training = rnn_model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validation, Y_validation))\n",
    "    #Model Evaluation\n",
    "    loss, accuracy = rnn_model.evaluate(X_train, Y_train, verbose = 1)\n",
    "    print(\"Loss: {0},\\nTraining Accuracy: {1}\".format(loss, accuracy))\n",
    "    print(\" \"*60)\n",
    "    loss, accuracy = rnn_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "    print(\"Loss: {0},\\nTesting Accuracy: {1}\".format(loss, accuracy))\n",
    "    \n",
    "    #Returning predicted set, test set and accuracy for further evaluation\n",
    "    Y_pred=rnn_model.predict(X_test)\n",
    "    return Y_pred,Y_test,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Fold Cross Validation of 70:10:20 split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "                        Cross Validation of 1 iteration is : \n",
      "******************************************************************************************\n",
      "Training - Validation(development) - Test set details :\n",
      "Training Set\n",
      "Input Shape is : (2817, 100)\n",
      "Output Shape is : (2817, 100, 47)\n",
      "**********************************************************************\n",
      "Validation(Development) Set\n",
      "Input Shape is : (314, 100)\n",
      "Output Shape is : (314, 100, 47)\n",
      "**********************************************************************\n",
      "Testing Set\n",
      "Input Shape is : (783, 100)\n",
      "Output Shape is : (783, 100, 47)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          3416400   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100, 128)          54912     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 100, 47)           6063      \n",
      "=================================================================\n",
      "Total params: 3,477,375\n",
      "Trainable params: 3,477,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "45/45 [==============================] - 9s 176ms/step - loss: 2.0963 - acc: 0.7072 - val_loss: 0.7629 - val_acc: 0.8170\n",
      "Epoch 2/15\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.6655 - acc: 0.8431 - val_loss: 0.4433 - val_acc: 0.9103\n",
      "Epoch 3/15\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.3591 - acc: 0.9280 - val_loss: 0.2354 - val_acc: 0.9544\n",
      "Epoch 4/15\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.1918 - acc: 0.9642 - val_loss: 0.1474 - val_acc: 0.9691\n",
      "Epoch 5/15\n",
      "45/45 [==============================] - 7s 157ms/step - loss: 0.1134 - acc: 0.9789 - val_loss: 0.1093 - val_acc: 0.9742\n",
      "Epoch 6/15\n",
      "45/45 [==============================] - 7s 163ms/step - loss: 0.0757 - acc: 0.9856 - val_loss: 0.0898 - val_acc: 0.9774\n",
      "Epoch 7/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.0566 - acc: 0.9886 - val_loss: 0.0792 - val_acc: 0.9793\n",
      "Epoch 8/15\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.0439 - acc: 0.9905 - val_loss: 0.0733 - val_acc: 0.9800\n",
      "Epoch 9/15\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.0345 - acc: 0.9922 - val_loss: 0.0698 - val_acc: 0.9803\n",
      "Epoch 10/15\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.0293 - acc: 0.9932 - val_loss: 0.0670 - val_acc: 0.9807\n",
      "Epoch 11/15\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.0253 - acc: 0.9940 - val_loss: 0.0657 - val_acc: 0.9809\n",
      "Epoch 12/15\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.0220 - acc: 0.9947 - val_loss: 0.0647 - val_acc: 0.9810\n",
      "Epoch 13/15\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.0192 - acc: 0.9955 - val_loss: 0.0644 - val_acc: 0.9809\n",
      "Epoch 14/15\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.0183 - acc: 0.9953 - val_loss: 0.0642 - val_acc: 0.9812\n",
      "Epoch 15/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.0164 - acc: 0.9960 - val_loss: 0.0641 - val_acc: 0.9809\n",
      "89/89 [==============================] - 2s 17ms/step - loss: 0.0126 - acc: 0.9971\n",
      "Loss: 0.012621824629604816,\n",
      "Training Accuracy: 0.9970926642417908\n",
      "                                                            \n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.0685 - acc: 0.9812\n",
      "Loss: 0.06851736456155777,\n",
      "Testing Accuracy: 0.9812005162239075\n",
      "******************************************************************************************\n",
      "                        Cross Validation of 2 iteration is : \n",
      "******************************************************************************************\n",
      "Training - Validation(development) - Test set details :\n",
      "Training Set\n",
      "Input Shape is : (2817, 100)\n",
      "Output Shape is : (2817, 100, 47)\n",
      "**********************************************************************\n",
      "Validation(Development) Set\n",
      "Input Shape is : (314, 100)\n",
      "Output Shape is : (314, 100, 47)\n",
      "**********************************************************************\n",
      "Testing Set\n",
      "Input Shape is : (783, 100)\n",
      "Output Shape is : (783, 100, 47)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          3416400   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100, 128)          54912     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 47)           6063      \n",
      "=================================================================\n",
      "Total params: 3,477,375\n",
      "Trainable params: 3,477,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "45/45 [==============================] - 8s 158ms/step - loss: 2.1058 - acc: 0.7046 - val_loss: 0.7320 - val_acc: 0.8327\n",
      "Epoch 2/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.6748 - acc: 0.8488 - val_loss: 0.4358 - val_acc: 0.9142\n",
      "Epoch 3/15\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.4037 - acc: 0.9190 - val_loss: 0.2492 - val_acc: 0.9531\n",
      "Epoch 4/15\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.2236 - acc: 0.9595 - val_loss: 0.1553 - val_acc: 0.9690\n",
      "Epoch 5/15\n",
      "45/45 [==============================] - 7s 160ms/step - loss: 0.1302 - acc: 0.9764 - val_loss: 0.1123 - val_acc: 0.9755\n",
      "Epoch 6/15\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.0866 - acc: 0.9839 - val_loss: 0.0911 - val_acc: 0.9782\n",
      "Epoch 7/15\n",
      "45/45 [==============================] - 7s 161ms/step - loss: 0.0635 - acc: 0.9875 - val_loss: 0.0795 - val_acc: 0.9798\n",
      "Epoch 8/15\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.0479 - acc: 0.9903 - val_loss: 0.0728 - val_acc: 0.9802\n",
      "Epoch 9/15\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.0388 - acc: 0.9918 - val_loss: 0.0685 - val_acc: 0.9806\n",
      "Epoch 10/15\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.0330 - acc: 0.9925 - val_loss: 0.0657 - val_acc: 0.9813\n",
      "Epoch 11/15\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.0274 - acc: 0.9935 - val_loss: 0.0638 - val_acc: 0.9815\n",
      "Epoch 12/15\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.0256 - acc: 0.9939 - val_loss: 0.0627 - val_acc: 0.9816\n",
      "Epoch 13/15\n",
      "45/45 [==============================] - 7s 149ms/step - loss: 0.0218 - acc: 0.9949 - val_loss: 0.0618 - val_acc: 0.9818\n",
      "Epoch 14/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.0194 - acc: 0.9953 - val_loss: 0.0610 - val_acc: 0.9824\n",
      "Epoch 15/15\n",
      "45/45 [==============================] - 7s 150ms/step - loss: 0.0181 - acc: 0.9956 - val_loss: 0.0609 - val_acc: 0.9819\n",
      "89/89 [==============================] - 1s 16ms/step - loss: 0.0142 - acc: 0.9966\n",
      "Loss: 0.014185618609189987,\n",
      "Training Accuracy: 0.996574342250824\n",
      "                                                            \n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.0632 - acc: 0.9821\n",
      "Loss: 0.06316061317920685,\n",
      "Testing Accuracy: 0.9820689558982849\n",
      "******************************************************************************************\n",
      "                        Cross Validation of 3 iteration is : \n",
      "******************************************************************************************\n",
      "Training - Validation(development) - Test set details :\n",
      "Training Set\n",
      "Input Shape is : (2817, 100)\n",
      "Output Shape is : (2817, 100, 47)\n",
      "**********************************************************************\n",
      "Validation(Development) Set\n",
      "Input Shape is : (314, 100)\n",
      "Output Shape is : (314, 100, 47)\n",
      "**********************************************************************\n",
      "Testing Set\n",
      "Input Shape is : (783, 100)\n",
      "Output Shape is : (783, 100, 47)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 300)          3416400   \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100, 128)          54912     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 100, 47)           6063      \n",
      "=================================================================\n",
      "Total params: 3,477,375\n",
      "Trainable params: 3,477,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 150ms/step - loss: 2.1378 - acc: 0.7053 - val_loss: 0.7645 - val_acc: 0.8264\n",
      "Epoch 2/15\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.6794 - acc: 0.8466 - val_loss: 0.4470 - val_acc: 0.9115\n",
      "Epoch 3/15\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.3828 - acc: 0.9235 - val_loss: 0.2429 - val_acc: 0.9556\n",
      "Epoch 4/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.2022 - acc: 0.9639 - val_loss: 0.1530 - val_acc: 0.9693\n",
      "Epoch 5/15\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.1228 - acc: 0.9774 - val_loss: 0.1126 - val_acc: 0.9750\n",
      "Epoch 6/15\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.0816 - acc: 0.9852 - val_loss: 0.0921 - val_acc: 0.9777\n",
      "Epoch 7/15\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.0580 - acc: 0.9886 - val_loss: 0.0805 - val_acc: 0.9793\n",
      "Epoch 8/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.0445 - acc: 0.9909 - val_loss: 0.0742 - val_acc: 0.9796\n",
      "Epoch 9/15\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.0362 - acc: 0.9921 - val_loss: 0.0703 - val_acc: 0.9806\n",
      "Epoch 10/15\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.0307 - acc: 0.9931 - val_loss: 0.0675 - val_acc: 0.9805\n",
      "Epoch 11/15\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.0266 - acc: 0.9937 - val_loss: 0.0661 - val_acc: 0.9811\n",
      "Epoch 12/15\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.0229 - acc: 0.9945 - val_loss: 0.0648 - val_acc: 0.9815\n",
      "Epoch 13/15\n",
      "45/45 [==============================] - 7s 162ms/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0645 - val_acc: 0.9814\n",
      "Epoch 14/15\n",
      "45/45 [==============================] - 7s 153ms/step - loss: 0.0175 - acc: 0.9959 - val_loss: 0.0639 - val_acc: 0.9813\n",
      "Epoch 15/15\n",
      "45/45 [==============================] - 7s 152ms/step - loss: 0.0165 - acc: 0.9960 - val_loss: 0.0638 - val_acc: 0.9816\n",
      "89/89 [==============================] - 1s 16ms/step - loss: 0.0131 - acc: 0.9971\n",
      "Loss: 0.013095468282699585,\n",
      "Training Accuracy: 0.9970571398735046\n",
      "                                                            \n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.0620 - acc: 0.9825\n",
      "Loss: 0.0619850791990757,\n",
      "Testing Accuracy: 0.9825031757354736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#Shuffling and splitting into 3 different sets for cross validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=.20, random_state=0)\n",
    "cv_scores=[0]*3\n",
    "itr=0\n",
    "#Initializing\n",
    "best_pred_set=None\n",
    "best_test_set=None\n",
    "best_accuracy=0 \n",
    "#For each split creating and evaluating model\n",
    "for train_idx,test_idx in cv.split(X):\n",
    "    itr+=1\n",
    "    print(\"*\"*90)\n",
    "    print(\"                        Cross Validation of {} iteration is : \".format(itr))\n",
    "    print(\"*\"*90)\n",
    "    Pred_Set,Test_Set,cv_scores[itr-1]=evaluate_model(X[train_idx],Y[train_idx],X[test_idx],Y[test_idx])\n",
    "    if cv_scores[itr-1]>best_accuracy:\n",
    "        best_accuracy=cv_scores[itr-1]\n",
    "        best_test_set=Test_Set\n",
    "        best_pred_set=Pred_Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the best model among the 3 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Testing Accuracy is : 0.9819242159525553\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Testing Accuracy is : {}\".format(sum(cv_scores)/len(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Testing Accuracy among all the folds is : 0.9825031757354736\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Testing Accuracy among all the folds is : {}\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for 3 folds are :\n",
      "0.9812005162239075 0.9820689558982849 0.9825031757354736\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies for 3 folds are :\")\n",
    "print(*cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the best prediction set are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.91846919e-01, 1.74480563e-04, 1.02738457e-04, ...,\n",
       "        1.10637746e-04, 2.47459568e-04, 2.30685415e-04],\n",
       "       [9.99713361e-01, 7.71289433e-06, 6.38070333e-06, ...,\n",
       "        2.92807385e-06, 9.04311491e-06, 8.31369289e-06],\n",
       "       [9.99865174e-01, 2.84575185e-06, 2.46485365e-06, ...,\n",
       "        9.43748773e-07, 3.52823236e-06, 3.73541570e-06],\n",
       "       ...,\n",
       "       [3.57720093e-03, 6.39729500e-01, 4.68909042e-03, ...,\n",
       "        7.03340105e-04, 1.74069707e-03, 1.57341466e-03],\n",
       "       [1.71360356e-04, 8.08609184e-04, 4.32083561e-06, ...,\n",
       "        9.12347787e-06, 3.79405128e-06, 3.40950828e-05],\n",
       "       [3.48258007e-04, 9.57011466e-08, 7.22553086e-05, ...,\n",
       "        2.97503393e-05, 1.83110769e-05, 1.67617036e-05]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Values of the best prediction set are :\")\n",
    "best_pred_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the best testing set are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Values of the best testing set are :\")\n",
    "best_test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding the predicted tags in the best_pred_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining an empty matrix of zeros of shape of best_pred_set\n",
    "out = np.zeros(best_pred_set.shape)\n",
    "#Finding the tag index for each sequence which has the highest probablity value \n",
    "idx = best_pred_set.argmax(axis=-1)\n",
    "#Setting that value to 1 and rest to 0\n",
    "out[np.arange(best_pred_set.shape[0])[:,None],np.arange(best_pred_set.shape[1]),idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  2, 10,  2,  4, 39,  7,  6,  2,  1,  8,  7,  1,  1,  2,  4,\n",
       "        3,  3, 11, 15,  4,  7,  1,  2, 24, 10, 10,  5,  7,  1,  9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the index havnig the max value among the 46 tag values for a certain sequence\n",
    "best_pred=np.argmax(out, axis=2)\n",
    "best_test=np.argmax(best_test_set,axis=2)\n",
    "#Actual Tags(Encoded) for the 2nd sequence in Test Set\n",
    "best_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  2, 10,  2,  4, 33, 19,  6,  2,  1,  8,  7,  1,  1,  2,  4,\n",
       "        1,  1, 11, 15,  4,  7,  7,  2, 24, 10, 10,  5,  7,  1,  9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted Tags(Encoded) for the 2nd sequence in Test Set\n",
    "best_pred[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-wise accuracy for the different tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive=[0]*(NUM_TAGS+1)\n",
    "actual_count=[0]*(NUM_TAGS+1)\n",
    "for i in range(best_test.shape[0]):\n",
    "    for j in range(best_test.shape[1]):\n",
    "        if best_test[i][j]==0: #Ignore if its 0 as it is present due to padding\n",
    "            continue\n",
    "        #if both are equal then increment count by 1 for true positive case\n",
    "        if best_test[i][j]==best_pred[i][j]:\n",
    "            true_positive[best_test[i][j]]+=1\n",
    "        actual_count[best_test[i][j]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "              class-wise accuracies of the different classes \n",
      "******************************************************************************************\n",
      "Accuracy of tag - class 1 is 92.61693080788558 %\n",
      "Accuracy of tag - class 2 is 98.15762538382803 %\n",
      "Accuracy of tag - class 3 is 86.83368869936035 %\n",
      "Accuracy of tag - class 4 is 99.45021380574221 %\n",
      "Accuracy of tag - class 5 is 97.72554965883245 %\n",
      "Accuracy of tag - class 6 is 91.61624891961971 %\n",
      "Accuracy of tag - class 7 is 81.35593220338984 %\n",
      "Accuracy of tag - class 8 is 100.0 %\n",
      "Accuracy of tag - class 9 is 100.0 %\n",
      "Accuracy of tag - class 10 is 92.45014245014245 %\n",
      "Accuracy of tag - class 11 is 90.06309148264984 %\n",
      "Accuracy of tag - class 12 is 83.1918505942275 %\n",
      "Accuracy of tag - class 13 is 93.86973180076629 %\n",
      "Accuracy of tag - class 14 is 99.52718676122932 %\n",
      "Accuracy of tag - class 15 is 100.0 %\n",
      "Accuracy of tag - class 16 is 86.41975308641975 %\n",
      "Accuracy of tag - class 17 is 91.92399049881234 %\n",
      "Accuracy of tag - class 18 is 99.70674486803519 %\n",
      "Accuracy of tag - class 19 is 87.29641693811075 %\n",
      "Accuracy of tag - class 20 is 86.4 %\n",
      "Accuracy of tag - class 21 is 99.43181818181817 %\n",
      "Accuracy of tag - class 22 is 100.0 %\n",
      "Accuracy of tag - class 23 is 100.0 %\n",
      "Accuracy of tag - class 24 is 100.0 %\n",
      "Accuracy of tag - class 25 is 100.0 %\n",
      "Accuracy of tag - class 26 is 98.125 %\n",
      "Accuracy of tag - class 27 is 100.0 %\n",
      "Accuracy of tag - class 28 is 71.26436781609196 %\n",
      "Accuracy of tag - class 29 is 79.1044776119403 %\n",
      "Accuracy of tag - class 30 is 35.714285714285715 %\n",
      "Accuracy of tag - class 31 is 100.0 %\n",
      "Accuracy of tag - class 32 is 58.69565217391305 %\n",
      "Accuracy of tag - class 33 is 92.85714285714286 %\n",
      "Accuracy of tag - class 34 is 100.0 %\n",
      "Accuracy of tag - class 35 is 29.411764705882355 %\n",
      "Accuracy of tag - class 36 is 100.0 %\n",
      "Accuracy of tag - class 37 is 100.0 %\n",
      "Accuracy of tag - class 38 is 100.0 %\n",
      "Accuracy of tag - class 39 is 0.0 %\n",
      "Accuracy of tag - class 40 is 0.0 %\n",
      "Accuracy of tag - class 41 is 100.0 %\n",
      "Accuracy of tag - class 42 is 100.0 %\n",
      "Accuracy of tag - class 43 is 0.0 %\n",
      "Accuracy of tag - class 44 is 0.0 %\n",
      "Accuracy of tag - class 45 is 0.0 %\n",
      "Accuracy of tag - class 46 is : NA \n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*90)\n",
    "print(\"              class-wise accuracies of the different classes \")\n",
    "print(\"*\"*90)\n",
    "class_accuracies=[]\n",
    "for i in range(1,NUM_TAGS+1):\n",
    "    if actual_count[i]!=0:\n",
    "        class_accuracies.append((true_positive[i]/actual_count[i])*100)\n",
    "        print(\"Accuracy of tag - class {} is {} %\".format(i,(class_accuracies[i-1])))\n",
    "    else:\n",
    "        class_accuracies.append(0)\n",
    "        print(\"Accuracy of tag - class {} is : NA \".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 8)) \n",
    "# creating the bar plot \n",
    "category_list=[str(i) for i in range(1,NUM_TAGS+1)]\n",
    "plt.bar(category_list, class_accuracies, color ='blue',width = 0.5) \n",
    "  \n",
    "plt.xlabel(\"tag - classes\") \n",
    "plt.ylabel(\"Accuracy in Percentage(%)\") \n",
    "plt.title(\"Accuracy of different tag - classes\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
